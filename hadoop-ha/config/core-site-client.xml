<?xml version="1.0" encoding="UTF-8"?>
<configuration>
  <!-- Use HA nameservice -->
  <property>
    <name>fs.defaultFS</name>
    <value>hdfs://mycluster</value>
  </property>
  
  <!-- Hadoop temporary directory -->
  <property>
    <name>hadoop.tmp.dir</name>
    <value>/tmp/hadoop</value>
  </property>
  
  <!-- Enable WebHDFS -->
  <property>
    <name>dfs.webhdfs.enabled</name>
    <value>true</value>
  </property>

  <!-- ZooKeeper Configuration -->
  <property>
    <name>ha.zookeeper.quorum</name>
    <value>localhost:2181</value>
  </property>

  <!-- HA Configuration for client -->
  <property>
    <name>dfs.nameservices</name>
    <value>mycluster</value>
  </property>
  
  <property>
    <name>dfs.ha.namenodes.mycluster</name>
    <value>nn1,nn2</value>
  </property>
  
  <property>
    <name>dfs.namenode.rpc-address.mycluster.nn1</name>
    <value>localhost:9820</value>
  </property>
  
  <property>
    <name>dfs.namenode.rpc-address.mycluster.nn2</name>
    <value>localhost:9821</value>
  </property>
  
  <property>
    <name>dfs.client.failover.proxy.provider.mycluster</name>
    <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
  </property>

  <!-- Force client to use hostname instead of IP -->
  <property>
    <name>dfs.client.use.datanode.hostname</name>
    <value>true</value>
  </property>

  <!-- Client should resolve DataNode hostnames to localhost -->
  <property>
    <name>dfs.datanode.hostname</name>
    <value>localhost</value>
  </property>
</configuration>